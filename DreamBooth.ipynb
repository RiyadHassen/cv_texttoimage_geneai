{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Finetune Dreambooth\n",
        "\n",
        "- Collect dataset of 20-30 images about the subject to be trained on different setting"
      ],
      "metadata": {
        "id": "mLGccMRPRVy8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8nljjYRRITO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install requirnments"
      ],
      "metadata": {
        "id": "iV208mEZTPTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/examples/dreambooth/train_dreambooth.py\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRGMjGXSTRk_",
        "outputId": "f25b12db-e681-47c3-f6dd-208beb81548b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Login to HuggingFace 🤗\n",
        "\n",
        "#@markdown You need to accept the model license before downloading or using the Stable Diffusion weights. Please, visit the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5), read the license and tick the checkbox if you agree. You have to be a registered user in 🤗 Hugging Face Hub, and you'll also need to use an access token for the code to work.\n",
        "# https://huggingface.co/settings/tokens\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token"
      ],
      "metadata": {
        "id": "VyWmHFtRTTvS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown If model weights should be saved directly in google drive (takes around 4-5 GB).\n",
        "save_to_gdrive = True #@param {type:\"boolean\"}\n",
        "if save_to_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "#@markdown Name/Path of the initial model.\n",
        "MODEL_NAME = \"runwayml/stable-diffusion-v1-5\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Enter the directory name to save model at.\n",
        "\n",
        "OUTPUT_DIR = \"stable_diffusion_weights/cats\" #@param {type:\"string\"}\n",
        "if save_to_gdrive:\n",
        "    OUTPUT_DIR = \"/content/drive/MyDrive/\" + OUTPUT_DIR\n",
        "else:\n",
        "    OUTPUT_DIR = \"/content/\" + OUTPUT_DIR\n",
        "\n",
        "print(f\"[*] Weights will be saved at {OUTPUT_DIR}\")\n",
        "\n",
        "!mkdir -p $OUTPUT_DIR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94gJXW7BU88c",
        "outputId": "2d0218f2-0041-4eef-d8a4-2dcdf5b64ea3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "[*] Weights will be saved at /content/drive/MyDrive/stable_diffusion_weights/cats\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also add multiple concepts here. Try tweaking `--max_train_steps` accordingly.\n",
        "\n",
        "concepts_list = [\n",
        "    {\n",
        "        \"instance_prompt\":      \"photo of zwx cat\",\n",
        "        \"class_prompt\":         \"photo of a cat\",\n",
        "        \"instance_data_dir\":    \"/content/data/zwx\",\n",
        "        \"class_data_dir\":       \"/content/data/cat\"\n",
        "    },\n",
        "#     {\n",
        "#         \"instance_prompt\":      \"photo of ukj person\",\n",
        "#         \"class_prompt\":         \"photo of a person\",\n",
        "#         \"instance_data_dir\":    \"/content/data/ukj\",\n",
        "#         \"class_data_dir\":       \"/content/data/person\"\n",
        "#     }\n",
        "]\n",
        "\n",
        "# `class_data_dir` contains regularization images\n",
        "import json\n",
        "import os\n",
        "for c in concepts_list:\n",
        "    os.makedirs(c[\"instance_data_dir\"], exist_ok=True)\n",
        "\n",
        "with open(\"concepts_list.json\", \"w\") as f:\n",
        "    json.dump(concepts_list, f, indent=4)"
      ],
      "metadata": {
        "id": "YMwMyiVyYW8-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Upload your images by running this cell.\n",
        "\n",
        "#@markdown OR\n",
        "\n",
        "#@markdown You can use the file manager on the left panel to upload (drag and drop) to each `instance_data_dir` (it uploads faster). You can also upload your own class images in `class_data_dir` if u don't wanna generate with SD.\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "for c in concepts_list:\n",
        "    print(f\"Uploading instance images for `{c['instance_prompt']}`\")\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(c['instance_data_dir'], filename)\n",
        "        shutil.move(filename, dst_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "VKs3DnFqaDO_",
        "outputId": "2e13d185-7966-4ff8-be99-dd038c744650"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading instance images for `photo of zwx cat`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d56989ed-d733-4dd3-a890-dfd95b141104\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d56989ed-d733-4dd3-a890-dfd95b141104\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 00.jpg to 00.jpg\n",
            "Saving 01.jpg to 01.jpg\n",
            "Saving 02.jpg to 02.jpg\n",
            "Saving 03.jpg to 03.jpg\n",
            "Saving 04.jpg to 04.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --pretrained_vae_name_or_path=\"stabilityai/sd-vae-ft-mse\" \\\n",
        "  --output_dir=$OUTPUT_DIR \\\n",
        "  --revision=\"fp16\" \\\n",
        "  --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "  --seed=1337 \\\n",
        "  --resolution=512 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --train_text_encoder \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --use_8bit_adam \\\n",
        "  --gradient_accumulation_steps=1 \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --lr_scheduler=\"constant\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --num_class_images=50 \\\n",
        "  --sample_batch_size=4 \\\n",
        "  --max_train_steps=800 \\\n",
        "  --save_interval=10000 \\\n",
        "  --save_sample_prompt=\"photo of zwx cat\" \\\n",
        "  --concepts_list=\"concepts_list.json\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jl8wNgIuaI3D",
        "outputId": "b57fcd8b-9fee-4b75-99d1-9752ad60188c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-19 20:33:50.628520: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-19 20:33:50.628626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-19 20:33:50.732582: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-19 20:33:52.442522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "config.json: 100% 547/547 [00:00<00:00, 3.11MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 233MB/s]\n",
            "model_index.json: 100% 543/543 [00:00<00:00, 2.79MB/s]\n",
            "unet/diffusion_pytorch_model.safetensors not found\n",
            "Fetching 15 files:   0% 0/15 [00:00<?, ?it/s]\n",
            "scheduler/scheduler_config.json: 100% 307/307 [00:00<00:00, 1.57MB/s]\n",
            "\n",
            "safety_checker/config.json: 100% 4.70k/4.70k [00:00<00:00, 23.0MB/s]\n",
            "\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 1.86MB/s]\n",
            "\n",
            "text_encoder/config.json: 100% 636/636 [00:00<00:00, 3.76MB/s]\n",
            "Fetching 15 files:   7% 1/15 [00:00<00:07,  1.91it/s]\n",
            "tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer/special_tokens_map.json: 100% 472/472 [00:00<00:00, 2.92MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 12.4MB/s]\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/246M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "unet/config.json: 100% 806/806 [00:00<00:00, 4.36MB/s]\n",
            "\n",
            "\n",
            "tokenizer/tokenizer_config.json: 100% 822/822 [00:00<00:00, 4.23MB/s]\n",
            "\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer/vocab.json:   0% 0.00/1.06M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "vae/config.json: 100% 609/609 [00:00<00:00, 3.18MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 26.4MB/s]\n",
            "\n",
            "pytorch_model.bin:   4% 10.5M/246M [00:00<00:03, 71.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:   2% 10.5M/608M [00:00<00:07, 76.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:   9% 21.0M/246M [00:00<00:03, 72.9MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:   3% 21.0M/608M [00:00<00:07, 76.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   1% 10.5M/1.72G [00:00<00:24, 69.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  13% 31.5M/246M [00:00<00:02, 82.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   1% 21.0M/1.72G [00:00<00:20, 83.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:   7% 41.9M/608M [00:00<00:05, 98.7MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  21% 52.4M/246M [00:00<00:02, 83.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   6% 10.5M/167M [00:00<00:02, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:   9% 52.4M/608M [00:00<00:06, 80.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   2% 41.9M/1.72G [00:00<00:20, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  26% 62.9M/246M [00:00<00:02, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  13% 21.0M/167M [00:00<00:02, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  10% 62.9M/608M [00:00<00:08, 62.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   3% 52.4M/1.72G [00:00<00:25, 64.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  30% 73.4M/246M [00:01<00:02, 67.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  19% 31.5M/167M [00:00<00:02, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  12% 73.4M/608M [00:01<00:08, 63.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   4% 62.9M/1.72G [00:00<00:25, 65.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  34% 83.9M/246M [00:01<00:02, 64.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  25% 41.9M/167M [00:00<00:02, 58.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   4% 73.4M/1.72G [00:01<00:24, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  14% 83.9M/608M [00:01<00:08, 62.9MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  38% 94.4M/246M [00:01<00:02, 67.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  31% 52.4M/167M [00:00<00:02, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  16% 94.4M/608M [00:01<00:08, 63.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   5% 83.9M/1.72G [00:01<00:26, 61.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  43% 105M/246M [00:01<00:02, 61.6MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 62.9M/167M [00:01<00:01, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  17% 105M/608M [00:01<00:08, 61.2MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   5% 94.4M/1.72G [00:01<00:26, 61.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  47% 115M/246M [00:01<00:02, 61.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  44% 73.4M/167M [00:01<00:01, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   6% 105M/1.72G [00:01<00:26, 60.8MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  19% 115M/608M [00:01<00:08, 60.1MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  51% 126M/246M [00:01<00:01, 60.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  50% 83.9M/167M [00:01<00:01, 60.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   7% 115M/1.72G [00:01<00:25, 62.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  21% 126M/608M [00:01<00:08, 58.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  55% 136M/246M [00:02<00:01, 59.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  56% 94.4M/167M [00:01<00:01, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   7% 126M/1.72G [00:01<00:25, 61.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  22% 136M/608M [00:02<00:08, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  63% 105M/167M [00:02<00:03, 19.1MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   8% 136M/1.72G [00:03<01:19, 19.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  60% 147M/246M [00:03<00:05, 18.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  69% 115M/167M [00:03<00:02, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  24% 147M/608M [00:03<00:24, 19.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   9% 147M/1.72G [00:03<01:00, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  64% 157M/246M [00:03<00:03, 24.5MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  26% 157M/608M [00:03<00:17, 25.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  81% 136M/167M [00:03<00:00, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  68% 168M/246M [00:03<00:02, 31.7MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  28% 168M/608M [00:03<00:13, 32.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  10% 168M/1.72G [00:03<00:39, 39.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  88% 147M/167M [00:03<00:00, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  72% 178M/246M [00:03<00:01, 38.6MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  29% 178M/608M [00:03<00:10, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  10% 178M/1.72G [00:03<00:34, 45.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  94% 157M/167M [00:03<00:00, 52.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  77% 189M/246M [00:04<00:01, 45.8MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  31% 189M/608M [00:04<00:08, 46.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  11% 189M/1.72G [00:04<01:11, 21.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.bin: 100% 167M/167M [00:04<00:00, 35.0MB/s]\n",
            "\n",
            "\n",
            "pytorch_model.bin:  33% 199M/608M [00:05<00:20, 20.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  12% 199M/1.72G [00:05<00:58, 26.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  34% 210M/608M [00:05<00:15, 25.2MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  89% 220M/246M [00:05<00:00, 30.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  12% 210M/1.72G [00:05<00:48, 31.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  36% 220M/608M [00:05<00:11, 32.6MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  94% 231M/246M [00:05<00:00, 36.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  13% 220M/1.72G [00:05<00:40, 37.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  38% 231M/608M [00:05<00:09, 40.4MB/s]\u001b[A\u001b[A\n",
            "pytorch_model.bin:  98% 241M/246M [00:05<00:00, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  13% 231M/1.72G [00:05<00:32, 45.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  40% 241M/608M [00:05<00:07, 48.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model.bin: 100% 246M/246M [00:05<00:00, 41.7MB/s]\n",
            "\n",
            "\n",
            "pytorch_model.bin:  41% 252M/608M [00:05<00:06, 54.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  43% 262M/608M [00:05<00:05, 63.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  15% 252M/1.72G [00:05<00:25, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  15% 262M/1.72G [00:05<00:23, 61.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  45% 273M/608M [00:06<00:05, 64.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  47% 283M/608M [00:08<00:29, 11.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  16% 273M/1.72G [00:09<02:24, 10.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  48% 294M/608M [00:09<00:23, 13.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  52% 315M/608M [00:09<00:12, 23.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  17% 294M/1.72G [00:09<01:23, 17.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  53% 325M/608M [00:09<00:10, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  18% 304M/1.72G [00:09<01:07, 20.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  55% 336M/608M [00:09<00:08, 32.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  18% 315M/1.72G [00:09<00:55, 25.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  57% 346M/608M [00:09<00:06, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  19% 325M/1.72G [00:09<00:44, 31.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  60% 367M/608M [00:10<00:04, 56.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  20% 346M/1.72G [00:09<00:30, 45.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  62% 377M/608M [00:10<00:03, 59.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  21% 367M/1.72G [00:10<00:22, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  64% 388M/608M [00:10<00:03, 64.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  23% 388M/1.72G [00:10<00:18, 73.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  67% 409M/608M [00:10<00:02, 85.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  24% 409M/1.72G [00:10<00:14, 90.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  71% 430M/608M [00:10<00:01, 101MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  25% 430M/1.72G [00:10<00:12, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  74% 451M/608M [00:10<00:01, 107MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  26% 451M/1.72G [00:10<00:12, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  78% 472M/608M [00:10<00:01, 104MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  27% 472M/1.72G [00:10<00:11, 112MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  81% 493M/608M [00:11<00:00, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  29% 493M/1.72G [00:11<00:11, 104MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  84% 514M/608M [00:11<00:00, 105MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  30% 514M/1.72G [00:11<00:10, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  88% 535M/608M [00:11<00:00, 116MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  31% 535M/1.72G [00:11<00:09, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  91% 556M/608M [00:11<00:00, 126MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  32% 556M/1.72G [00:11<00:08, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  95% 577M/608M [00:11<00:00, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  34% 577M/1.72G [00:11<00:08, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  35% 598M/1.72G [00:11<00:07, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:  98% 598M/608M [00:11<00:00, 124MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_model.bin: 100% 608M/608M [00:12<00:00, 50.4MB/s]\n",
            "Fetching 15 files:  27% 4/15 [00:12<00:37,  3.41s/it]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 650M/1.72G [00:12<00:06, 177MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  40% 682M/1.72G [00:12<00:05, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  41% 713M/1.72G [00:12<00:05, 198MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  43% 744M/1.72G [00:12<00:04, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  45% 776M/1.72G [00:12<00:04, 212MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  47% 807M/1.72G [00:12<00:04, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  49% 839M/1.72G [00:12<00:04, 214MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  51% 870M/1.72G [00:13<00:05, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  52% 902M/1.72G [00:13<00:05, 163MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  54% 933M/1.72G [00:13<00:04, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  56% 965M/1.72G [00:13<00:03, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  58% 996M/1.72G [00:13<00:03, 185MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  59% 1.02G/1.72G [00:14<00:04, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  60% 1.04G/1.72G [00:14<00:03, 181MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  62% 1.07G/1.72G [00:14<00:03, 199MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  63% 1.09G/1.72G [00:14<00:03, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  65% 1.11G/1.72G [00:14<00:03, 176MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  66% 1.13G/1.72G [00:14<00:03, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  67% 1.15G/1.72G [00:14<00:03, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  68% 1.17G/1.72G [00:14<00:03, 164MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  70% 1.20G/1.72G [00:15<00:03, 174MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  71% 1.23G/1.72G [00:15<00:02, 191MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  73% 1.26G/1.72G [00:15<00:02, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  75% 1.29G/1.72G [00:15<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  77% 1.32G/1.72G [00:15<00:01, 206MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  78% 1.34G/1.72G [00:15<00:01, 201MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  79% 1.36G/1.72G [00:15<00:01, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  81% 1.38G/1.72G [00:16<00:01, 171MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  82% 1.41G/1.72G [00:16<00:01, 172MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  83% 1.43G/1.72G [00:16<00:01, 178MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  85% 1.46G/1.72G [00:16<00:01, 203MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  87% 1.49G/1.72G [00:16<00:01, 218MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  88% 1.52G/1.72G [00:16<00:00, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  90% 1.55G/1.72G [00:16<00:00, 223MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  92% 1.58G/1.72G [00:16<00:00, 228MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  94% 1.61G/1.72G [00:17<00:00, 240MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  96% 1.65G/1.72G [00:17<00:00, 248MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  98% 1.68G/1.72G [00:17<00:00, 241MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin: 100% 1.72G/1.72G [00:17<00:00, 98.3MB/s]\n",
            "Fetching 15 files: 100% 15/15 [00:18<00:00,  1.22s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
            "  warnings.warn(\n",
            "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
            "03/19/2024 20:34:18 - INFO - __main__ - Number of class images to sample: 50.\n",
            "Generating class images: 100% 13/13 [02:47<00:00, 12.86s/it]\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "For effortless bug reporting copy-paste your error into this form: https://docs.google.com/forms/d/e/1FAIpQLScPB8emS3Thkp66nvqwmjTEgxp8Y9ufuWTzFyr9kJ5AoI47dQ/viewform?usp=sf_link\n",
            "================================================================================\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:105: UserWarning: /usr/lib64-nvidia did not contain libcudart.so as expected! Searching further paths...\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//172.28.0.1'), PosixPath('8013'), PosixPath('http')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-1bcgvq2qa0rlo --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/paths.py:27: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 122\n",
            "CUDA SETUP: TODO: compile library for specific version: libbitsandbytes_cuda122.so\n",
            "CUDA SETUP: Defaulting to libbitsandbytes.so...\n",
            "CUDA SETUP: CUDA detection failed. Either CUDA driver not installed, CUDA not installed, or you have multiple conflicting CUDA libraries!\n",
            "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train_dreambooth.py\", line 869, in <module>\n",
            "    main(args)\n",
            "  File \"/content/train_dreambooth.py\", line 571, in main\n",
            "    import bitsandbytes as bnb\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/__init__.py\", line 6, in <module>\n",
            "    from .autograd._functions import (\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py\", line 5, in <module>\n",
            "    import bitsandbytes.functional as F\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/functional.py\", line 13, in <module>\n",
            "    from .cextension import COMPILED_WITH_CUDA, lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 41, in <module>\n",
            "    lib = CUDALibrary_Singleton.get_instance().lib\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 37, in get_instance\n",
            "    cls._instance.initialize()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/bitsandbytes/cextension.py\", line 27, in initialize\n",
            "    raise Exception('CUDA SETUP: Setup Failed!')\n",
            "Exception: CUDA SETUP: Setup Failed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4rj_KSra3S5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}